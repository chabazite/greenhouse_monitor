{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f4c6a50c-ea63-45c1-b5fb-c9e06682ed1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import image_uris\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "s3_bucket = 'greenhouseprocessed'\n",
    "\n",
    "# List files in the directory\n",
    "files = fs.ls(f'{s3_bucket}/')\n",
    "\n",
    "\n",
    "# Read each file into a DataFrame and concatenate them\n",
    "df_list = [pd.read_parquet(f's3://{file}', storage_options={'anon': False}) for file in files]#\n",
    "full_df = pd.concat(df_list, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a116ecd4-6718-417a-8077-6c6f014e6ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove heat_index (calculated field)\n",
    "full_df = full_df.drop(columns = ['heat_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b1ff22f0-4462-418e-97c5-77f5a71169be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove datetime prior to start date (2023-11-26 03:02:45)\n",
    "\n",
    "full_df = full_df[full_df['datetime']>= '2023-11-26 03:02:45']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c490ddd5-63c4-4ce5-a4c0-540aa728d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a50b7e2f-5d77-4073-b603-fd67e5efb76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Aggregate Data down to the Minutes, as DeepAR can only predict down to 1 Min. We will take the mean of all the values over 1 min\n",
    "full_df = full_df.resample('1min').mean()\n",
    "full_df = full_df.sort_values('datetime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eb682080-2af5-43f6-8322-e5cd0909e12a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df['start'] = full_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "429ea1ba-fa8f-452a-8c10-1281abe33c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df['start'] = full_df['start'].dt.strftime('%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "25e81279-1707-4c90-a1c8-a50b967ec3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time series array creation. 1 Hour blocks\n",
    "# Define the window size (60 minutes for 1 hour)\n",
    "window_size = 60\n",
    "sliding_windows = []\n",
    "\n",
    "for start in range(len(full_df) - window_size + 1):\n",
    "    end = start + window_size\n",
    "    window = full_df[start:end]\n",
    "    sliding_windows.append({\n",
    "        \"start\": str(window['start'].iloc[0]),\n",
    "        \"target\": window['temperature'].tolist(),\n",
    "        \"dynamic_feat\": [window['humidity'].tolist()]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7db37df5-0071-42cd-aa70-af05044d23ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the index for the split\n",
    "train_size = int(len(sliding_windows) * 0.8)\n",
    "\n",
    "# Split the DataFrame\n",
    "train_df = sliding_windows[:train_size]\n",
    "test_df = sliding_windows[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e16fb485-b495-4bbc-91e5-30b1098c2249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# to convert each time series to a single line JSON string\n",
    "def convert_to_line_delimited_json(list_of_dicts):\n",
    "    return '\\n'.join(json.dumps(obj) for obj in list_of_dicts)\n",
    "\n",
    "# Convert to line-delimited JSON\n",
    "train_json = convert_to_line_delimited_json(train_df)\n",
    "test_json = convert_to_line_delimited_json(test_df)\n",
    "\n",
    "# Save to a file\n",
    "with open('train.json', 'w') as file:\n",
    "    file.write(train_json)\n",
    "with open('test.json', 'w') as file:\n",
    "    file.write(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a8dd133a-ce0a-42b8-bea2-2139d4c0c65b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://greenhousetraintest/test/test.json'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload to S3\n",
    "sagemaker.Session().upload_data(path='train.json', bucket='greenhousetraintest', key_prefix='train')\n",
    "sagemaker.Session().upload_data(path='test.json', bucket='greenhousetraintest', key_prefix='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4fc56870-b5a4-406e-b4eb-4b2da1036a18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    " #Set your region (e.g., 'us-east-2')\n",
    "region = sagemaker.Session().boto_region_name\n",
    "\n",
    "# Get the DeepAR image URI\n",
    "image_uri = image_uris.retrieve(framework='forecasting-deepar', region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7a20f917-8bd6-479d-8f1f-bbedd5d3d145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Parmas\n",
    "bucket = 'greenhousemodels'\n",
    "train_path = 's3://greenhousetraintest/train/train.json'\n",
    "test_path = 's3://greenhousetraintest/test/test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "03f90df5-4e77-4332-9de3-a4ec04d52e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: forecasting-deepar-2023-11-28-01-46-12-324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-28 01:46:12 Starting - Starting the training job...\n",
      "2023-11-28 01:46:28 Starting - Preparing the instances for training......\n",
      "2023-11-28 01:47:28 Downloading - Downloading input data...\n",
      "2023-11-28 01:48:02 Training - Downloading the training image.....................\n",
      "2023-11-28 01:51:29 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mRunning custom environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '30', 'epochs': '20', 'num_dynamic_feat': '1', 'prediction_length': '30', 'time_freq': '1min'}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': '1', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '30', 'epochs': '20', 'prediction_length': '30', 'time_freq': '1min'}\u001b[0m\n",
      "\u001b[34mProcess 8 is a worker.\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] random_seed is None\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Training set statistics:\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Real time series\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] number of time series: 1310\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] number of observations: 78600\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] mean target length: 60.0\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] min/mean/max target: 67.63999938964844/69.92807381122773/73.91254425048828\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] mean abs(target): 69.92807381122773\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] contains missing values: no\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Test set statistics:\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Real time series\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] number of time series: 328\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] number of observations: 19680\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] mean target length: 60.0\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] min/mean/max target: 68.36000061035156/69.26554838351117/72.68000030517578\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] mean abs(target): 69.26554838351117\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] contains missing values: no\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] #memory_usage::<batchbuffer> = 3.3740234375 mb\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136296.7918456, \"EndTime\": 1701136296.9329073, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 139.984130859375, \"count\": 1, \"min\": 139.984130859375, \"max\": 139.984130859375}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:36 INFO 139781948995392] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:37 INFO 139781948995392] #memory_usage::<model> = 51 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136296.9329946, \"EndTime\": 1701136297.1594534, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 367.4936294555664, \"count\": 1, \"min\": 367.4936294555664, \"max\": 367.4936294555664}}}\u001b[0m\n",
      "\u001b[34m[01:51:37] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.374.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 20480 bytes with malloc directly\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:37 INFO 139781948995392] Epoch[0] Batch[0] avg_epoch_loss=4.587748\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:37 INFO 139781948995392] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.587748050689697\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:39 INFO 139781948995392] Epoch[0] Batch[5] avg_epoch_loss=4.367967\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:39 INFO 139781948995392] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=4.367966810862224\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:39 INFO 139781948995392] Epoch[0] Batch [5]#011Speed: 338.43 samples/sec#011loss=4.367967\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:41 INFO 139781948995392] processed a total of 1280 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136297.1595194, \"EndTime\": 1701136301.448051, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"update.time\": {\"sum\": 4288.403511047363, \"count\": 1, \"min\": 4288.403511047363, \"max\": 4288.403511047363}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:41 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=298.46888783877694 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:41 INFO 139781948995392] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:41 INFO 139781948995392] #quality_metric: host=algo-1, epoch=0, train loss <loss>=4.206295442581177\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:42 INFO 139781948995392] Epoch[1] Batch[0] avg_epoch_loss=3.880843\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:42 INFO 139781948995392] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.880842685699463\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:43 INFO 139781948995392] Epoch[1] Batch[5] avg_epoch_loss=3.696544\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:43 INFO 139781948995392] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.6965439319610596\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:43 INFO 139781948995392] Epoch[1] Batch [5]#011Speed: 390.87 samples/sec#011loss=3.696544\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] Epoch[1] Batch[10] avg_epoch_loss=3.532792\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=3.3362896919250487\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] Epoch[1] Batch [10]#011Speed: 441.81 samples/sec#011loss=3.336290\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] processed a total of 1350 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136301.4481304, \"EndTime\": 1701136305.3671465, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3918.544054031372, \"count\": 1, \"min\": 3918.544054031372, \"max\": 3918.544054031372}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=344.50684680470687 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.532792004671964\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] Epoch[2] Batch[0] avg_epoch_loss=3.102600\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:45 INFO 139781948995392] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.102599859237671\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:47 INFO 139781948995392] Epoch[2] Batch[5] avg_epoch_loss=2.959721\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:47 INFO 139781948995392] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=2.9597206513086953\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:47 INFO 139781948995392] Epoch[2] Batch [5]#011Speed: 423.28 samples/sec#011loss=2.959721\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:48 INFO 139781948995392] Epoch[2] Batch[10] avg_epoch_loss=2.728444\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:48 INFO 139781948995392] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=2.450911355018616\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:48 INFO 139781948995392] Epoch[2] Batch [10]#011Speed: 448.49 samples/sec#011loss=2.450911\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:48 INFO 139781948995392] processed a total of 1318 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136305.367215, \"EndTime\": 1701136308.8327029, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3465.1365280151367, \"count\": 1, \"min\": 3465.1365280151367, \"max\": 3465.1365280151367}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:48 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=380.347579569953 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:48 INFO 139781948995392] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:48 INFO 139781948995392] #quality_metric: host=algo-1, epoch=2, train loss <loss>=2.7284436984495684\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:49 INFO 139781948995392] Epoch[3] Batch[0] avg_epoch_loss=2.473620\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:49 INFO 139781948995392] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.4736199378967285\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:50 INFO 139781948995392] Epoch[3] Batch[5] avg_epoch_loss=2.315915\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:50 INFO 139781948995392] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=2.3159153858820596\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:50 INFO 139781948995392] Epoch[3] Batch [5]#011Speed: 458.35 samples/sec#011loss=2.315915\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] Epoch[3] Batch[10] avg_epoch_loss=2.195499\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=2.0509989261627197\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] Epoch[3] Batch [10]#011Speed: 453.29 samples/sec#011loss=2.050999\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] processed a total of 1359 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136308.8327708, \"EndTime\": 1701136312.184001, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3350.024461746216, \"count\": 1, \"min\": 3350.024461746216, \"max\": 3350.024461746216}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=405.65167521728824 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] #quality_metric: host=algo-1, epoch=3, train loss <loss>=2.19549881328236\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] Epoch[4] Batch[0] avg_epoch_loss=1.997795\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:52 INFO 139781948995392] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=1.9977953433990479\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:54 INFO 139781948995392] Epoch[4] Batch[5] avg_epoch_loss=2.030405\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:54 INFO 139781948995392] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.030404726664225\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:54 INFO 139781948995392] Epoch[4] Batch [5]#011Speed: 354.05 samples/sec#011loss=2.030405\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:55 INFO 139781948995392] Epoch[4] Batch[10] avg_epoch_loss=1.918427\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:55 INFO 139781948995392] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=1.7840528964996338\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:55 INFO 139781948995392] Epoch[4] Batch [10]#011Speed: 445.06 samples/sec#011loss=1.784053\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:55 INFO 139781948995392] processed a total of 1362 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136312.1841063, \"EndTime\": 1701136315.9701662, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3785.557270050049, \"count\": 1, \"min\": 3785.557270050049, \"max\": 3785.557270050049}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:55 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=359.7772231695683 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:55 INFO 139781948995392] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:55 INFO 139781948995392] #quality_metric: host=algo-1, epoch=4, train loss <loss>=1.9184266220439563\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:56 INFO 139781948995392] Epoch[5] Batch[0] avg_epoch_loss=2.247511\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:56 INFO 139781948995392] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.2475109100341797\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:57 INFO 139781948995392] Epoch[5] Batch[5] avg_epoch_loss=2.053404\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:57 INFO 139781948995392] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.0534040331840515\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:57 INFO 139781948995392] Epoch[5] Batch [5]#011Speed: 449.01 samples/sec#011loss=2.053404\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] Epoch[5] Batch[10] avg_epoch_loss=1.922648\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=1.7657410860061646\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] Epoch[5] Batch [10]#011Speed: 443.85 samples/sec#011loss=1.765741\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] processed a total of 1383 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136315.9702492, \"EndTime\": 1701136319.361814, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3391.160249710083, \"count\": 1, \"min\": 3391.160249710083, \"max\": 3391.160249710083}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=407.8116887052059 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] #quality_metric: host=algo-1, epoch=5, train loss <loss>=1.9226481481031938\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] Epoch[6] Batch[0] avg_epoch_loss=2.255172\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:51:59 INFO 139781948995392] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.2551722526550293\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:01 INFO 139781948995392] Epoch[6] Batch[5] avg_epoch_loss=2.063020\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:01 INFO 139781948995392] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.0630197525024414\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:01 INFO 139781948995392] Epoch[6] Batch [5]#011Speed: 453.52 samples/sec#011loss=2.063020\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:03 INFO 139781948995392] Epoch[6] Batch[10] avg_epoch_loss=1.944957\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:03 INFO 139781948995392] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=1.8032820701599122\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:03 INFO 139781948995392] Epoch[6] Batch [10]#011Speed: 332.71 samples/sec#011loss=1.803282\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:03 INFO 139781948995392] processed a total of 1340 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136319.361891, \"EndTime\": 1701136323.2579882, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3895.6308364868164, \"count\": 1, \"min\": 3895.6308364868164, \"max\": 3895.6308364868164}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:03 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=343.95829980163103 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:03 INFO 139781948995392] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:03 INFO 139781948995392] #quality_metric: host=algo-1, epoch=6, train loss <loss>=1.9449571696194736\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:04 INFO 139781948995392] Epoch[7] Batch[0] avg_epoch_loss=1.775623\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:04 INFO 139781948995392] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=1.7756234407424927\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:05 INFO 139781948995392] Epoch[7] Batch[5] avg_epoch_loss=1.717611\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:05 INFO 139781948995392] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=1.717610736687978\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:05 INFO 139781948995392] Epoch[7] Batch [5]#011Speed: 394.34 samples/sec#011loss=1.717611\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] Epoch[7] Batch[10] avg_epoch_loss=1.694453\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=1.6666634798049926\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] Epoch[7] Batch [10]#011Speed: 453.39 samples/sec#011loss=1.666663\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] processed a total of 1349 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136323.2580805, \"EndTime\": 1701136327.2287772, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3970.0727462768555, \"count\": 1, \"min\": 3970.0727462768555, \"max\": 3970.0727462768555}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=339.78205968319367 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] #quality_metric: host=algo-1, epoch=7, train loss <loss>=1.6944528926502576\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] Epoch[8] Batch[0] avg_epoch_loss=1.691354\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:07 INFO 139781948995392] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=1.6913537979125977\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:09 INFO 139781948995392] Epoch[8] Batch[5] avg_epoch_loss=1.620381\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:09 INFO 139781948995392] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=1.6203807592391968\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:09 INFO 139781948995392] Epoch[8] Batch [5]#011Speed: 447.72 samples/sec#011loss=1.620381\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:10 INFO 139781948995392] processed a total of 1274 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136327.2288568, \"EndTime\": 1701136330.3163664, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3086.9836807250977, \"count\": 1, \"min\": 3086.9836807250977, \"max\": 3086.9836807250977}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:10 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=412.6863152210547 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:10 INFO 139781948995392] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:10 INFO 139781948995392] #quality_metric: host=algo-1, epoch=8, train loss <loss>=1.5821258783340455\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:10 INFO 139781948995392] Epoch[9] Batch[0] avg_epoch_loss=1.525483\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:10 INFO 139781948995392] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=1.52548348903656\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:12 INFO 139781948995392] Epoch[9] Batch[5] avg_epoch_loss=1.495171\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:12 INFO 139781948995392] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=1.495171348253886\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:12 INFO 139781948995392] Epoch[9] Batch [5]#011Speed: 452.60 samples/sec#011loss=1.495171\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:13 INFO 139781948995392] Epoch[9] Batch[10] avg_epoch_loss=1.469153\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:13 INFO 139781948995392] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=1.4379316329956056\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:13 INFO 139781948995392] Epoch[9] Batch [10]#011Speed: 445.00 samples/sec#011loss=1.437932\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:13 INFO 139781948995392] processed a total of 1350 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136330.316437, \"EndTime\": 1701136333.6915078, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3374.3624687194824, \"count\": 1, \"min\": 3374.3624687194824, \"max\": 3374.3624687194824}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:13 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=400.06163805026216 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:13 INFO 139781948995392] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:13 INFO 139781948995392] #quality_metric: host=algo-1, epoch=9, train loss <loss>=1.4691532958637585\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:14 INFO 139781948995392] Epoch[10] Batch[0] avg_epoch_loss=1.853500\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:14 INFO 139781948995392] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=1.8535000085830688\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:15 INFO 139781948995392] Epoch[10] Batch[5] avg_epoch_loss=1.730850\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:15 INFO 139781948995392] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=1.730850358804067\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:15 INFO 139781948995392] Epoch[10] Batch [5]#011Speed: 457.08 samples/sec#011loss=1.730850\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] Epoch[10] Batch[10] avg_epoch_loss=1.638917\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=1.5285972118377686\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] Epoch[10] Batch [10]#011Speed: 450.84 samples/sec#011loss=1.528597\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] processed a total of 1365 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136333.6915846, \"EndTime\": 1701136337.0377514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3345.635414123535, \"count\": 1, \"min\": 3345.635414123535, \"max\": 3345.635414123535}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=407.9742150474789 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] #progress_metric: host=algo-1, completed 55.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] #quality_metric: host=algo-1, epoch=10, train loss <loss>=1.6389171101830222\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] Epoch[11] Batch[0] avg_epoch_loss=1.917946\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:17 INFO 139781948995392] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=1.917946219444275\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:19 INFO 139781948995392] Epoch[11] Batch[5] avg_epoch_loss=1.684938\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:19 INFO 139781948995392] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=1.6849377353986104\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:19 INFO 139781948995392] Epoch[11] Batch [5]#011Speed: 413.01 samples/sec#011loss=1.684938\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:20 INFO 139781948995392] Epoch[11] Batch[10] avg_epoch_loss=1.590522\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:20 INFO 139781948995392] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=1.4772226810455322\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:20 INFO 139781948995392] Epoch[11] Batch [10]#011Speed: 451.33 samples/sec#011loss=1.477223\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:20 INFO 139781948995392] processed a total of 1349 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136337.0378163, \"EndTime\": 1701136340.5386033, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3500.22292137146, \"count\": 1, \"min\": 3500.22292137146, \"max\": 3500.22292137146}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:20 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=385.38887759733694 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:20 INFO 139781948995392] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:20 INFO 139781948995392] #quality_metric: host=algo-1, epoch=11, train loss <loss>=1.5905218016017566\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:21 INFO 139781948995392] Epoch[12] Batch[0] avg_epoch_loss=1.952982\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:21 INFO 139781948995392] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=1.9529820680618286\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:22 INFO 139781948995392] Epoch[12] Batch[5] avg_epoch_loss=1.709363\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:22 INFO 139781948995392] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=1.7093627055486043\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:22 INFO 139781948995392] Epoch[12] Batch [5]#011Speed: 460.52 samples/sec#011loss=1.709363\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:23 INFO 139781948995392] Epoch[12] Batch[10] avg_epoch_loss=1.616827\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:23 INFO 139781948995392] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=1.5057848930358886\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:23 INFO 139781948995392] Epoch[12] Batch [10]#011Speed: 445.56 samples/sec#011loss=1.505785\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:23 INFO 139781948995392] processed a total of 1323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136340.538704, \"EndTime\": 1701136343.9019313, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3362.713098526001, \"count\": 1, \"min\": 3362.713098526001, \"max\": 3362.713098526001}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:23 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=393.4182569057434 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:23 INFO 139781948995392] #progress_metric: host=algo-1, completed 65.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:23 INFO 139781948995392] #quality_metric: host=algo-1, epoch=12, train loss <loss>=1.6168273362246426\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:24 INFO 139781948995392] Epoch[13] Batch[0] avg_epoch_loss=1.465067\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:24 INFO 139781948995392] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=1.4650665521621704\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:25 INFO 139781948995392] Epoch[13] Batch[5] avg_epoch_loss=1.470362\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:25 INFO 139781948995392] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=1.4703623453776042\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:25 INFO 139781948995392] Epoch[13] Batch [5]#011Speed: 455.52 samples/sec#011loss=1.470362\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] Epoch[13] Batch[10] avg_epoch_loss=1.492229\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=1.5184688329696656\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] Epoch[13] Batch [10]#011Speed: 448.82 samples/sec#011loss=1.518469\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] processed a total of 1361 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136343.9020088, \"EndTime\": 1701136347.261392, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3358.982801437378, \"count\": 1, \"min\": 3358.982801437378, \"max\": 3358.982801437378}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=405.16660062287707 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] #quality_metric: host=algo-1, epoch=13, train loss <loss>=1.492228930646723\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] Epoch[14] Batch[0] avg_epoch_loss=1.409713\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:27 INFO 139781948995392] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.4097130298614502\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:29 INFO 139781948995392] Epoch[14] Batch[5] avg_epoch_loss=1.404814\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:29 INFO 139781948995392] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=1.4048144022623699\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:29 INFO 139781948995392] Epoch[14] Batch [5]#011Speed: 443.25 samples/sec#011loss=1.404814\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:30 INFO 139781948995392] Epoch[14] Batch[10] avg_epoch_loss=1.388071\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:30 INFO 139781948995392] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=1.367978024482727\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:30 INFO 139781948995392] Epoch[14] Batch [10]#011Speed: 447.69 samples/sec#011loss=1.367978\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:30 INFO 139781948995392] processed a total of 1399 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136347.2614846, \"EndTime\": 1701136350.6532395, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3391.2627696990967, \"count\": 1, \"min\": 3391.2627696990967, \"max\": 3391.2627696990967}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:30 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=412.51645902225727 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:30 INFO 139781948995392] #progress_metric: host=algo-1, completed 75.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:30 INFO 139781948995392] #quality_metric: host=algo-1, epoch=14, train loss <loss>=1.388070594180714\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:31 INFO 139781948995392] Epoch[15] Batch[0] avg_epoch_loss=1.764381\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:31 INFO 139781948995392] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=1.764380931854248\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:32 INFO 139781948995392] Epoch[15] Batch[5] avg_epoch_loss=1.578320\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:32 INFO 139781948995392] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=1.5783204833666484\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:32 INFO 139781948995392] Epoch[15] Batch [5]#011Speed: 460.02 samples/sec#011loss=1.578320\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] Epoch[15] Batch[10] avg_epoch_loss=1.526640\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=1.464622712135315\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] Epoch[15] Batch [10]#011Speed: 436.14 samples/sec#011loss=1.464623\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] processed a total of 1417 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136350.6533194, \"EndTime\": 1701136354.3209226, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3667.1833992004395, \"count\": 1, \"min\": 3667.1833992004395, \"max\": 3667.1833992004395}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=386.38597348926436 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.5094479223092396\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] Epoch[16] Batch[0] avg_epoch_loss=2.155819\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:34 INFO 139781948995392] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.1558189392089844\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:36 INFO 139781948995392] Epoch[16] Batch[5] avg_epoch_loss=1.697541\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:36 INFO 139781948995392] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=1.6975411574045818\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:36 INFO 139781948995392] Epoch[16] Batch [5]#011Speed: 451.74 samples/sec#011loss=1.697541\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:37 INFO 139781948995392] Epoch[16] Batch[10] avg_epoch_loss=1.643306\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:37 INFO 139781948995392] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=1.5782243728637695\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:37 INFO 139781948995392] Epoch[16] Batch [10]#011Speed: 457.64 samples/sec#011loss=1.578224\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:37 INFO 139781948995392] processed a total of 1314 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136354.3210032, \"EndTime\": 1701136357.661868, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3340.285062789917, \"count\": 1, \"min\": 3340.285062789917, \"max\": 3340.285062789917}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:37 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=393.3651677987193 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:37 INFO 139781948995392] #progress_metric: host=algo-1, completed 85.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:37 INFO 139781948995392] #quality_metric: host=algo-1, epoch=16, train loss <loss>=1.6433062553405762\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:38 INFO 139781948995392] Epoch[17] Batch[0] avg_epoch_loss=1.354622\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:38 INFO 139781948995392] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=1.3546217679977417\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:39 INFO 139781948995392] Epoch[17] Batch[5] avg_epoch_loss=1.503739\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:39 INFO 139781948995392] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=1.5037391583124797\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:39 INFO 139781948995392] Epoch[17] Batch [5]#011Speed: 427.71 samples/sec#011loss=1.503739\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] Epoch[17] Batch[10] avg_epoch_loss=1.473086\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=1.4363025665283202\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] Epoch[17] Batch [10]#011Speed: 448.93 samples/sec#011loss=1.436303\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] processed a total of 1390 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136357.6619544, \"EndTime\": 1701136361.1047854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3442.4221515655518, \"count\": 1, \"min\": 3442.4221515655518, \"max\": 3442.4221515655518}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=403.7716139416278 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] #quality_metric: host=algo-1, epoch=17, train loss <loss>=1.4730861620469526\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] Epoch[18] Batch[0] avg_epoch_loss=1.338579\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:41 INFO 139781948995392] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=1.3385789394378662\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:43 INFO 139781948995392] Epoch[18] Batch[5] avg_epoch_loss=1.348470\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:43 INFO 139781948995392] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=1.3484699527422588\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:43 INFO 139781948995392] Epoch[18] Batch [5]#011Speed: 461.39 samples/sec#011loss=1.348470\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:44 INFO 139781948995392] Epoch[18] Batch[10] avg_epoch_loss=1.336294\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:44 INFO 139781948995392] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=1.3216827392578125\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:44 INFO 139781948995392] Epoch[18] Batch [10]#011Speed: 442.19 samples/sec#011loss=1.321683\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:44 INFO 139781948995392] processed a total of 1335 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136361.1048622, \"EndTime\": 1701136364.4913964, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3385.976791381836, \"count\": 1, \"min\": 3385.976791381836, \"max\": 3385.976791381836}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:44 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=394.2626510532138 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:44 INFO 139781948995392] #progress_metric: host=algo-1, completed 95.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:44 INFO 139781948995392] #quality_metric: host=algo-1, epoch=18, train loss <loss>=1.336293946612965\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:45 INFO 139781948995392] Epoch[19] Batch[0] avg_epoch_loss=1.426142\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:45 INFO 139781948995392] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=1.4261418581008911\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:46 INFO 139781948995392] Epoch[19] Batch[5] avg_epoch_loss=1.362122\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:46 INFO 139781948995392] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=1.3621223370234172\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:46 INFO 139781948995392] Epoch[19] Batch [5]#011Speed: 452.35 samples/sec#011loss=1.362122\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] Epoch[19] Batch[10] avg_epoch_loss=1.299341\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=1.2240042209625244\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] Epoch[19] Batch [10]#011Speed: 453.24 samples/sec#011loss=1.224004\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] processed a total of 1356 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136364.4914575, \"EndTime\": 1701136367.8479128, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 3355.825901031494, \"count\": 1, \"min\": 3355.825901031494, \"max\": 3355.825901031494}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] #throughput_metric: host=algo-1, train throughput=404.0620661820554 records/second\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] #quality_metric: host=algo-1, epoch=19, train loss <loss>=1.2993413751775569\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] Final loss: 1.2993413751775569 (occurred at epoch 19)\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] #quality_metric: host=algo-1, train final_loss <loss>=1.2993413751775569\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 WARNING 139781948995392] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:47 INFO 139781948995392] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136367.8479738, \"EndTime\": 1701136368.032567, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 183.76708030700684, \"count\": 1, \"min\": 183.76708030700684, \"max\": 183.76708030700684}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:48 INFO 139781948995392] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136368.03264, \"EndTime\": 1701136368.0984006, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 249.64404106140137, \"count\": 1, \"min\": 249.64404106140137, \"max\": 249.64404106140137}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:48 INFO 139781948995392] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:48 INFO 139781948995392] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136368.0984669, \"EndTime\": 1701136368.109106, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 10.587453842163086, \"count\": 1, \"min\": 10.587453842163086, \"max\": 10.587453842163086}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:48 INFO 139781948995392] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:48 INFO 139781948995392] #memory_usage::<batchbuffer> = 3.3740234375 mb\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:48 INFO 139781948995392] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136368.1091585, \"EndTime\": 1701136368.1116982, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.04029273986816406, \"count\": 1, \"min\": 0.04029273986816406, \"max\": 0.04029273986816406}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136368.1117563, \"EndTime\": 1701136375.075884, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 6964.23077583313, \"count\": 1, \"min\": 6964.23077583313, \"max\": 6964.23077583313}}}\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, RMSE): 1.3852496357917794\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, mean_absolute_QuantileLoss): 8873.920090399848\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, mean_wQuantileLoss): 0.013002141442821533\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.1]): 0.004720193703443005\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.2]): 0.009037228830435702\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.3]): 0.012942905653984309\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.4]): 0.016016853274537956\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.5]): 0.017746139003151765\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.6]): 0.017866115068931127\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.7]): 0.016429079868617205\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.8]): 0.013480298539727039\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #test_score (algo-1, wQuantileLoss[0.9]): 0.008780459042565695\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #quality_metric: host=algo-1, test RMSE <loss>=1.3852496357917794\u001b[0m\n",
      "\u001b[34m[11/28/2023 01:52:55 INFO 139781948995392] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.013002141442821533\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1701136375.075956, \"EndTime\": 1701136375.1015675, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 5.209445953369141, \"count\": 1, \"min\": 5.209445953369141, \"max\": 5.209445953369141}, \"totaltime\": {\"sum\": 78720.4110622406, \"count\": 1, \"min\": 78720.4110622406, \"max\": 78720.4110622406}}}\u001b[0m\n",
      "\n",
      "2023-11-28 01:53:15 Uploading - Uploading generated training model\n",
      "2023-11-28 01:53:15 Completed - Training job completed\n",
      "Training seconds: 348\n",
      "Billable seconds: 348\n"
     ]
    }
   ],
   "source": [
    "# Define the estimator\n",
    "estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path='s3://{}/output'.format(bucket),\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "# Set required hyperparameters for DeepAR\n",
    "estimator.set_hyperparameters(\n",
    "    time_freq='1min',         \n",
    "    epochs=20, \n",
    "    num_dynamic_feat = 1,\n",
    "    context_length=30,         # 30 minutes since our total time series has 60 values \n",
    "    prediction_length=30       # Predicting 30 minutes into the future\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "estimator.fit({'train': train_path, 'test': test_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409855f6-75ed-48f5-a3a1-3c77a9bd1aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6eb23bd0-fd40-4524-8719-654bbe83424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: forecasting-deepar-2023-11-28-01-46-12-324\n",
      "Image URI: 566113047672.dkr.ecr.us-east-2.amazonaws.com/forecasting-deepar:1\n"
     ]
    }
   ],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "response = sagemaker_client.list_training_jobs(\n",
    "    MaxResults=10,\n",
    "    SortBy='CreationTime',\n",
    "    SortOrder='Descending'\n",
    ")\n",
    "\n",
    "# Iterate through the jobs to find your DeepAR training job\n",
    "for job in response['TrainingJobSummaries']:\n",
    "    job_name = job['TrainingJobName']\n",
    "    job_details = sagemaker_client.describe_training_job(TrainingJobName=job_name)\n",
    "    if 'deepar' in job_details['AlgorithmSpecification']['TrainingImage']:\n",
    "        print(f\"Job Name: {job_name}\")\n",
    "        print(f\"Image URI: {job_details['AlgorithmSpecification']['TrainingImage']}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707a18f1-edea-40ee-a986-921f49f5e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "model_name = 'TimeSeries'\n",
    "model_arn = 'arn:aws:sagemaker:us-east-2:516411340133:model-package/TimeSeries/1'\n",
    "\n",
    "response = sagemaker_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'ModelPackageName': model_arn,\n",
    "    },\n",
    "    ExecutionRoleArn='arn:aws:iam::516411340133:role/service-role/AmazonSageMaker-ExecutionRole-20231125T182973'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87f404f6-7945-4d97-bd01-b9410b25ea44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-2:516411340133:endpoint-config/timeseries-endpoint-config',\n",
       " 'ResponseMetadata': {'RequestId': 'd07aeb0c-911b-459a-9380-d5c59d7a8b33',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd07aeb0c-911b-459a-9380-d5c59d7a8b33',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '107',\n",
       "   'date': 'Tue, 28 Nov 2023 02:47:17 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_config_name = 'timeseries-endpoint-config'\n",
    "sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'ModelName': model_name,\n",
    "            'InstanceType': 'ml.t2.medium',\n",
    "            'InitialInstanceCount': 1\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4b9070-df17-4027-b204-0cf8b3d7509b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointArn': 'arn:aws:sagemaker:us-east-2:516411340133:endpoint/timeseries-endpoint',\n",
       " 'ResponseMetadata': {'RequestId': '0d904f3a-b7ff-4127-a382-d2c28f1a5271',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0d904f3a-b7ff-4127-a382-d2c28f1a5271',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '87',\n",
       "   'date': 'Tue, 28 Nov 2023 02:47:24 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = 'timeseries-endpoint'\n",
    "\n",
    "sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70325932-5f3e-4e49-b30c-ebf8a7d87e83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AccessDeniedException) when calling the Invoke operation: User: arn:aws:sts::516411340133:assumed-role/AmazonSageMaker-ExecutionRole-20231125T182973/SageMaker is not authorized to perform: lambda:InvokeFunction on resource: arn:aws:lambda:us-east-2:516411340133:function:greenhouse-inference because no identity-based policy allows the lambda:InvokeFunction action",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m function_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreenhouse-inference\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Invoke the Lambda function\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlambda_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFunctionName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mInvocationType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRequestResponse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 'Event' for async\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Print the response\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:535\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:980\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    978\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    979\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDeniedException) when calling the Invoke operation: User: arn:aws:sts::516411340133:assumed-role/AmazonSageMaker-ExecutionRole-20231125T182973/SageMaker is not authorized to perform: lambda:InvokeFunction on resource: arn:aws:lambda:us-east-2:516411340133:function:greenhouse-inference because no identity-based policy allows the lambda:InvokeFunction action"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize the Lambda client\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "# Function name\n",
    "function_name = 'greenhouse-inference'\n",
    "\n",
    "# Invoke the Lambda function\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=function_name,\n",
    "    InvocationType='RequestResponse'  # 'Event' for async\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2b151-6ff4-4bac-89d3-1c8d251f29b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
